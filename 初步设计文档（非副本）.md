- ## 系统架构

  整体架构采用分布式的方式，包括Coordinator、Worker和Aggregator三个主要组件。

  1. **Coordinator（协调节点）：** 负责任务的分配和调度，管理整个系统的状态信息。
  2. **Worker（工作节点）：** 负责更新Git仓库、处理数据。可部署在各个家庭服务器上，无需公网IP。
  3. **Aggregator（聚合节点）：** 负责汇总各个Worker数据，从worker上拉取更新，并提供统一的服务接口给外部用户。Aggregator拥有公网IP，可供外部访问。

  

  ## 组件功能

  1. **Coordinator：**

     - 轻量级节点，拥有公网IP
     - 读取配置文件，管理数据。
     - 负责任务的分配和调度，将Git仓库URL分配给不同的Worker。
     - 与Aggregator交互。

     需要保证Coordinator的轻量级-> 

     1、高效任务调度算法+状态管理（避免不必要的计算和存储开销）

     2、需要保证其设计和功能的简化

     3、异步和并发处理

  2. **Worker：**

     - 从Git托管服务商（如GitHub、GitLab、Gitee）更新Git仓库数据，并实现增量同步。
     - 提供服务接口，响应Aggregator和Coordinator的请求。
     - 将本地状态和数据汇报给Coordinator。

  3. **Aggregator：**

     - 从各个Worker收集数据，并进行汇总。
     - 拥有公网IP，提供统一的服务接口给外部用户，例如提交任务、获取数据等。

  

  > **【worker/aggregator是否可合并? 成为一个模块里的两种运行模式：partial/full模式】**
  >
  > 可行。
  >
  > **Partial模式：** 在Partial模式下充当Worker的角色，负责从上游Git托管服务拉取指定的Git仓库数据并进行增量同步。它会定期轮询上游仓库，根据更新活跃度自适应地执行Git Pull操作频率。此模式下的核心功能是实现Git仓库的增量同步。
  >
  > **Full模式：** 在Full模式下充当Aggregator的角色，负责整体协调和服务提供。它会接收来自Partial模式的数据，并将所有拉取的仓库数据集中在一起。在Full模式中，还包含处理API请求、动态添加/更新Git URL等功能。此模式下的核心功能是对外提供API接口，允许用户按需触发Git仓库的拉取操作，并管理Git仓库的配置信息。

  

  ## 通信方式

  1. **Coordinator与Worker之间：**

     基于低延迟、高性能要求，可使用轻量级RPC来实现通信。

     Worker向Coordinator注册自己的状态，接收分配的任务，并定期汇报任务执行状态和结果

  2. **Aggregator与Worker之间：** 

     同样可使用RPC来实现通信。

     Aggregator向Worker请求最新数据

     wfg: Aggregator是否可以直接git fetch方式访问Worker? Worker直接起一个本地git server服务即可。
     不过要求Worker与Aggregator之间建立一种代理或者隧道。因为Worker没有公网IP，通常Aggregator无法主动直接访问Worker。

     git push to Aggregator?
     安全性 对公众开放 危险 会被攻击

  3. **Coordinator与Aggregator之间：** 

     这两者之间的通信需要更稳定和可靠的公共接口-> 可使用HTTP协议来实现

     Coordinator将从Worker收集到的数据请求发送给Aggregator，Aggregator进行数据汇总和处理后，将结果返回给Coordinator。

  4. **外部用户与Aggregator之间的通信：** 用户可通过HTTP API与Aggregator交互，提交任务、获取数据等操作。

  

  ## 数据存储

  ### a git tree to store git urls

  git_urls/
    dir/files 1000 urls per file
      - git_url:
        key: val
      - git_url:

  ### Coordinator
  ### Worker

  database: Elasticsearch （NoSQL）

  ### db table

  **`coordinator`** -> run elastic.client -> 数据库维护url list

  ES index: 'git_urls'
  ```json
  (
  	id: ..,
  	git_url:
	key: val
	workers: [worker_id1, worker_id2]
  )
  ```

  ES index: 'workers' # also includes aggregator
  ```json
  {
  	worker_id:
	pub_ip:
	pub_port:
	role: worker/aggregator
	alive:
	last_alive_time:
  }
  
  **`worker`** -> 自己维护repo的元数据（struct）（主要为了优先级pri服务，不需要持久化）
  
  一个worker挂了，coordinator将当前此worker上维护的repo下发给其他worker（较为平均），此时只需要将其他元数据置0，pri置为max（从pri_queue中获取max pri）
  
  ```c
  // worker自己维护
  (
  	name = 'repo_name',
      url = git_url,
      pri = repo_pri,
      
  	last_clone_time = ...,
  	last_clone_attempt = ...,
  	fail_clone_cnt= ...,
  	...
  )
  ```

  

  ？【belong_worker】

  worker和coordinator建立好连接之后再根据hash计算出此项

  ？【worker如何知道哪个url是自己维护的-> connect send / belong_worker_port】{

  	1、`belong_worker_url`：ES  search

  }

  

  

  # 数据结构

  - 配置文件格式
  - 磁盘repos dir layout
  - 数据库表
  - API/消息格式
  - 内部数据结构

  ....

  

  ## 仓库下发worker机制【hash机制】

  Coordinator中存有仓库URL list，采用一致性哈希算法来分配对应的worker。

  由于在分布式集群中worker节点的个数会不定时调整（增加n个worker或n个worker挂机的情况），如果采用常规哈希，在面对节点数量变化时选择重新去仓库列表源Coordinator中大规模进行仓库的重新分配，效率会很低且耗时间。

  考虑节点数量变化的场景，可以采用一致性哈希算法去解决。

  

  将repo哈希值映射到0-n空间中，且将这个范围首尾相连形成一个环。再解决worker负载不均的问题（当worker数量少时，有种情况是如果当前workerA挂了，那么原本workerA维护的n个仓库将全部由顺时针的下个workerB进行维护，导致负载不均），在一致性哈希的基础上引入虚拟worker的概念，一个真实worker对应n个虚拟worker。代价非常小，只需增加一个map维护真实节点与虚拟节点的映射关系即可。

  映射过程如下：

  Coordinator给出一个URL-> hash-> 对应到对应的worker

  hash过程如下：

  - 计算虚拟worker(使用worker的IP地址)的哈希值，放在环上。
  - 计算仓库（使用仓库URL）的哈希值，对哈希值进行判断-> 顺时针寻找到的第一个节点，就是应选取对应的worker。

  *（可参考图“一致性哈希.png”，其中key即为repo，peer即为worker）*

  ![](https://github.com/yanyanran/pictures/blob/main/%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C.png?raw=true)

  【?】插入新worker后，旧worker.next上的仓库是否需要取消其在worker上的维护？

  

  

  ##  POLL interval 自适应算法

  可延用git-mirror.rb中的逻辑在各worker中。

  new_10_threads并行-> queue.pop

  main_worker_loop-> push_git_queue-> get_repo_priority计算优先级

  interval核心在于`get_repo_priority` 和`cal_priority`：根据repo update history和fail_cnt来计算仓库的优先级(step每次叠加)

  `get_repo_priority`：repo is clone? -> (no) default **step**< clone_fail_cnt + 每个步骤的时间间隔常量 >

  -> (yes) call cal_priority

  `cal_priority`：check last commit time -> (time is 0) no commit, use default **step**

  -> 立方根化**interval** = time.now - last_commit_time 作为step与old_pri相加

  

  通过这种方式保持最近更新的仓库优先级较高（数值越大优先级越高），从而更快获取更新。


worker
  - repo_urls to poll
  - git_repos[repo_url].push_interval # 历史可统计的，上游软件push的间隔
      => log or sqrt (git_repos[repo_url].push_interval)
  - github/gitee rate limit # 常数
=>
  - git_repos[repo_url].poll_interval = A * B / C


  ## 故障检测和自动恢复机制

  1、 coordinator hangup

  

  2、 worker hangup

  一个worker挂了，根据【hash机制】coordinator将当前此worker上维护的repo下发给其他worker（分配较为平均）。此时只需要将其他元数据置0，pri置为max（从pri_queue中获取max pri）

  

  3、Aggregator hangup

  

  ...

  

  ## Config_file

  ...

  

  ## **功能列表：**

  **Story 1: Pull Upstream Repo**

  - 功能：从上游GitHub拉取指定Git仓库数据进行增量同步。
  - 包含的操作：
    - 从上游Git托管服务下载指定Git仓库的代码和历史记录。
    - 实现增量同步，只拉取新的提交，避免重复下载已有的数据。
    - 定期轮询上游仓库，根据更新活跃度自适应间隔进行Git Pull操作。
  - 输入：无（自动定时任务或系统内部触发）
  - 输出：Git仓库最新的提交数据或增量更新的提交数据。

  **Story 2: GitHub Webhook**

  - 功能：通过GitHub的Webhook机制实现Git仓库的自动同步。
  - 包含的操作：
    - 注册GitHub Webhook，将仓库的更新事件推送到系统中。
    - 根据接收到的Webhook消息，识别出哪个Git仓库有更新。
    - 触发相应的Worker执行Git Pull操作，拉取更新的数据。
  - 输入：GitHub Webhook消息（包含更新的Git仓库URL等信息）
  - 输出：无（触发Git Pull操作）

  **Story 3: On Demand (API)**

  - 功能：提供API接口，允许外部用户按需触发Git仓库的拉取操作。
  - 包含的操作：
    - 设计API接口，接收外部用户提交的Git仓库URL和拉取请求。
    - 根据API请求，将拉取任务分配给合适的Worker进行处理。
    - Worker执行Git Pull操作，获取最新的仓库数据，并将结果返回给用户。
  - 输入：外部用户提交的拉取任务请求（包含Git仓库URL和其他相关信息）

  - 输出：任务状态和结果数据。

  **Story 4: Dynamic Add/Update Git URLs (API)**

  - 功能：提供API接口，允许动态添加或更新需要拉取的Git仓库URL。
  - 包含的操作：
    - 设计API接口，接收外部用户提交的Git仓库URL和相关信息。
    - 将新的Git仓库URL添加到系统中，或者更新已有的Git仓库URL的相关信息。
    - 根据情况将新增或更新的Git仓库URL分配给合适的Worker进行处理。
  - 输入：外部用户提交的Git仓库URL和相关信息
  - 输出：Git仓库的添加/更新状态信息。 

  

  ## db table

  - table xxx

  每个模块的部署形式 具体的东西，配置、命令、数据

  worker 

  - loop: POLL upstream git urls
  - got message, action

  worker<>aggregator<>coordinator
  worker<>coordinator speed 10MB/s
  aggregator<>coordinator speed 100MB/s

  

  ## 启动流程

  - #### coordinator
	cood_config_file:
	listen port
	git_urls git repo url
	db connect way

local disk space:
	git_urls git repo

startup:
    read cood_config_file -> ( git clone/fetch/update urls_git_repo ) 
    load all git_urls git content to memory、create data structure （buf）in memory
    read db (about workers)

event loop:
	on worker register:
	on worker register its local urls:
	on worker tell one url new status 404/new_commit:

    new thread-> git fetch urls_git_repo on time：

func:
	monitor_git_urls_git on new thread:
    ```ruby
        loop:
            fetch_info = %x(git -C #{urls_git_repo} fetch)
            if fetch_info.include('->') # have new commit
	    for added repos:
	        assign worker
                #【?】如何知道哪部分增量添加了？
		git log, check +/- lines
                update_database(); 
	    for deleted repos:
	        tell worker to del
                update_database(); 
    ```

    listen
    
    new thread【?】-> send keepalive to worker（on time）


scheduler algorithm:
- avoid thrashing (worker1 online => 1 minute/hour later => worker2 oneline => )
  - tell worker1 to remove work list in time
- on worker online:
  - don't tell worker1 all urls at once, one batch at a time
- on worker offline
  - re-assign according to new consistent hash
  - not prefer: if some old workers have local cache, can tell them to poll for now (complex, not by consistent hash)
    
  - #### worker
  
  config file:
  	where is coordinator
  disk path
	
  git repos disk layout:
  	raw local git repos
  
  in-memory data:
  	git urls that have raw local git repos

startup:
    connect to coordinator
    scan per-url git dir, get local_urls list
    tell coordinator

event loop:
    on add new url request: get from coordinator new urls to process
    on del old url request: 
    on fetch old url request: do local git fetch

    on ping request: receive keepalive request -> ack to coordinator

func:
	fetch_repo:
		if found git url 404
			API tell coordinator
		if network error
			arrange local retries
		if disk error
			API tell coordinator I'm down


  - aggregator
    scan per-url git dir, get local_urls list &
    connect to coordinator
    report local_urls list to coordinator

  

  

​    

  crash, disk down, network down

  一致性
  概念定义
  需求列表
  DFX列表
  模块列表
  哪些数据 在哪里 怎么传递
  config file form?

  1M urls store in a git tree
  1 file store 1000 url?
  1k files, each file 1k urls, 100kb per file
  100MB data
  only coordinator git clone urls config file 

  db store which data?
  disk data, dir layout

  

  

  ## 功能/API列表

  ### worker

  - loop: poll upstream repo in regular interval
  - on message (API): poll upstream repo on demand
  - tell coordinator: which git repo has new data; has error
  - api_1

  do_xxx
  伪代码

  

  ### aggregator

  

  ### coordinator

  - maintain urls
  - assign a url set to some worker (mapping url<>worker can be computed from hash algo)

  



## API设计

1. **提交任务API（On Demand）：**

   - 接口：POST /api/tasks

   - 输入：

     ```
     {
       "git_url": "https://github.com/username/repo.git",
       "additional_params": { /* 可选的其他参数 */ }
     }
     ```

   - 输出：

     ```
     {
       "task_id": "123456",
       "status": "pending"
     }
     ```

2. **获取任务状态API：**

   - 接口：GET /api/tasks/{task_id}

   - 输出：

     ```
     {
       "task_id": "123456",
       "status": "running",
       "progress": "50%",
       "result": null /* 或者包含任务结果的数据 */
     }
     ```

3. **动态添加/更新Git URL API：**

   - 接口：POST /api/git_urls

   - 输入：

     ```
     {
       "git_url": "https://github.com/username/repo.git",
       "additional_info": { /* 可选的其他信息 */ }
     }
     ```

   - 输出：

     ```
     {
       "git_url": "https://github.com/username/repo.git",
       "status": "added"
     }
     ```

**数据结构：**

1. 任务数据结构：

   ```
   {
     "task_id": "123456",
     "status": "running", /* 任务状态：running, pending, success, failure 等 */
     "progress": "50%", /* 可选的任务进度信息 */
     "result": { /* 可选的任务执行结果数据 */ },
     "created_at": "2023-07-27T12:00:00Z",
     "updated_at": "2023-07-27T12:30:00Z"
   }
   ```

2. Git仓库数据结构：

   ```
   {
     "git_url": "https://github.com/username/repo.git",
     "additional_info": { /* 可选的其他信息 */ },
     "last_updated": "2023-07-27T12:00:00Z",
     "status": "active" /* 仓库状态：active, inactive 等 */
   }
   ```







------

1. Coordinator分配任务：系统预先配置好需要拉取的Git仓库URL列表，并存储在Coordinator中。Coordinator负责将这些Git仓库URL分配给不同的Worker进行处理。
2. Worker更新Git仓库：Worker接收到来自Coordinator的任务分配后，从上游Git托管服务（如GitHub、GitLab、Gitee等）更新指定的Git仓库数据，并实现增量同步。Worker定期轮询上游仓库，根据更新活跃度自适应间隔进行Git Pull操作。
3. Worker汇报状态：Worker执行Git Pull操作后，将本地状态和数据汇报给Coordinator，以便系统管理和任务调度。
4. Coordinator处理任务结果：Coordinator接收到来自Worker的任务执行状态和结果后，可能将结果返回给Aggregator，或者直接处理任务结果，取决于系统的具体设计。
5. Aggregator汇总数据：Aggregator负责从各个Worker节点收集数据，并进行汇总处理。它将所有拉取的仓库数据集中在一起，为后续的用户查询提供统一的数据接口。
6. 用户获取数据：外部用户可以通过Aggregator提供的API接口，根据任务ID或其他查询条件，获取之前拉取的Git仓库数据。
7. 动态管理：系统可以支持动态管理Git仓库URL列表，可以随时添加或更新需要拉取的Git仓库URL。
8. GitHub Webhook支持：在系统配置了GitHub Webhook的情况下，当Git仓库有更新时，GitHub会向Aggregator发送Webhook消息，触发相应的任务调度和Git Pull操作。